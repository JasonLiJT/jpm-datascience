{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python \n",
    "\n",
    "## Module 2: Mining and visualising real-world data\n",
    "\n",
    "In this module you will learn how to load the online retail dataset in Python, visualise and summarise it to produce insights that will guide your machine learning endevours in the next modules. You will learn how to plot data and calculate summary statistics to build a dataset from which you will ultimately try to predict future customer behaviour.\n",
    "\n",
    "\n",
    "### Learning Activity: Loading the Python libraries\n",
    "\n",
    "First you need to load the required Python libraries. Libraries are extensions to the base python that add functionality or help to make tasks more convenient to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compatibility with python2 and 3\n",
    "from __future__ import print_function, division\n",
    "\n",
    "# numerical capacity\n",
    "import scipy as scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib setup\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plotly setup\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "init_notebook_mode()\n",
    "\n",
    "# extra tools\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D \n",
    "import visplots\n",
    "\n",
    "# the tools we will use from SKLEARN\n",
    "\n",
    "# GENERAL SKLEARN TOOLS\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# UNSUPERVISED LEARNING MODULE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "# DTS and RFS MODULE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SVM MODULE\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "The dataset we will be using throughout this workshop is an *adapted and aggregated* version of the online retail case study, available from the UCI Machine Learning repository (https://archive.ics.uci.edu/ml/datasets/Online+Retail). The dataset has been designed for this workshop with the purpose of modelling the behaviour of customers (\"returning\" vs. \"non-returning\" customers) based on their activity (such as balance, max spent and number of orders, among others).\n",
    "\n",
    "### Learning Activity: Importing the data\n",
    "\n",
    "As a first step we load the dataset from the provided `retail_data.csv` file with `pandas`. To achieve this you will use the `.read_csv()` method from Pandas. We just need to point to the location of the dataset and indicate under what name we want to store the data, i.e. `retail`. \n",
    "\n",
    "Once the data has been loaded, you can look at the first few instances using the `.head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the data and explore the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to numpy array and check the dimensionality\n",
    "\n",
    "# Check the dimensionality using the .shape method of the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Split the data into input features, X, and outputs, y\n",
    "\n",
    "Subsequently, we need to split our initial dataset into the data matrix _X_ (independent variable) and the associated class vector _y_ (dependent or target variable). The input features, _X_,  are the variables that you use to predict the outcome. In this data set, there are ten input features stored in columns 1-10 (index 0-9, although the upper bound is not included so the range for indexing is 0:10), all of which have continuous values. The output label, _y_, holds the information of whether the customer has returned or not (\"yes\" vs. \"no\"), and is stored in the final (eleventh) column (index 10). To split the data, we need to assign the columns of the input features and the columns of the output labels to different arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split to input matrix X and class vector y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.astype(float)` indicates that we want to treat the entries of the matrix as real numbers (floating point numbers), before no type was assigned, the matrix was considered to be of type `object`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split to input matrix X and class vector y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try printing the size of the input matrix X and class vector y using the \"shape\" command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the dimensions of X and y\n",
    "\n",
    "# Explore X and y if you want to make sure it corresponds to what you expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Visualisation is an integral part of Data Science. Exploratory data analysis (EDA) is the field dealing with the analysis of data sets as a means of summarising their main characteristics, most often using visual methods.\n",
    "\n",
    "Plotly is an online collaborative data analysis and graphing tool that we will use in order to construct fully interactive graphs. The Plotly API allows you to access all of the library's interactive functionality directly from Python (or other programming languages such as R, JavaScript and MATLAB, among others). Crucially, Plotly has recently been made **open-source**, which now enables plotting **offline** without requiring access to their API. _Plotly Offline_ brings interactive Plotly graphs to the _offline_ Jupyter (IPython) Notebook environment.\n",
    "\n",
    "### Learning Activity:  Investigate the y frequencies\n",
    "\n",
    "An important aspect to understand before applying any classification algorithm is how the output labels are distributed. Are they evenly distributed or not? Imbalances in distribution of labels can often lead to poor classification results for the minority class even if the classification results for the majority class are very good.\n",
    "\n",
    "Use `scipy.stats.itemfreq` applied to `y` to get the y frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the y frequencies using the scipy.stats.itemfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our current dataset, you can see that the _y_ values are categorical (i.e. they can only take one of a discrete set of values) and have a non-numeric representation, \"yes\" vs. \"no\". This can be problematic for scikit-learn and plotting functions in Python, since they assume numerical values, so we need to map the text categories to numerical representations using `LabelEncoder`  and the `fit_transform()` function from the `preprocessing` module.\n",
    "\n",
    "1. define an instance of the `LabelEncoder` class from the `preprocessing` module\n",
    "2. apply the `fit_transform` method of that instance to `y`\n",
    "3. explore the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the categorical to numeric values, and print the y frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the class frequencies is a good way to get a feel for how the data is distributed. As a simple example, try plotting the frequencies of the class labels (held in yFreq), \"1\" and \"0\" (corresponding to \"yes\" and \"no\" respectively), and see how they are distributed using a barplot from Plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the y frequencies in a barplot with Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "More examples on Plotly barplots can be found at https://plot.ly/python/bar-charts/. In addition, a full list of arguments on barplots can be found at https://plot.ly/python/reference/#bar/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Data scaling\n",
    "\n",
    "It is usually advisable to scale your data prior to fitting a classification model to avoid attributes with\n",
    "greater numeric ranges dominating those with smaller numeric ranges. In order to investigate the range and descriptive statistics of our features, we can apply the `describe()` function from `pandas` to the original `retail` DataFrame (**_not_** the numpy array!). For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retail.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots are a powerful visual aid, commonly used in order to investigate simultaneously the range differences of the input features. Boxplots are a standardised way of displaying the distribution of the data based on the \"five number summary\" (minimum, first quartile, median, third quartile, and maximum). For example, try and plot the features of the raw matrix X using the script for the boxplots. Try adapting the plot to make sure you understand how everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a boxplot of the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways of scaling but one common scaling mechanism is auto-scaling, where for each\n",
    "column, the values are centred around the mean and divided by their standard deviation. This scaling\n",
    "mechanism can be applied by calling the `scale()` function in scikit-learn’s `preprocessing` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# redefine X so that it corresponds to the scaled version obtained \n",
    "# by applying the scale function from the preprocessing module to X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to re-run the previous plotting script and have a look at the outcome of the boxplot after scaling. Alternatively, \n",
    "if you feel more adventurous, you create a more enhanced version of the boxplot. You can find more online examples at https://plot.ly/python/box-plots/, and also a full list of boxplot arguments at https://plot.ly/python/reference/#box.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a boxplot of the scaled data (simple or enhanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Investigate the relationship between input features\n",
    "\n",
    "You can visualise the relationship between two variables (features) using a simple scatter plot. This step can give you a good first indication of the ML model model to apply and its complexity (linear vs. non-linear). At this stage, let’s plot the first two variables against each other. We can also relate associations between features to their _y_ classifications by making the colour of the points dependent on the corresponding _y_ value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an enhanced scatter plot of the first two features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Examples of Plotly scatterplots can be found at https://plot.ly/python/line-and-scatter/ (or for a list of arguments refer to https://plot.ly/python/reference/#scatter/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Activity:  Try plotting different combinations of three features (f1, f2, f3) in the same plot.\n",
    "\n",
    "\n",
    "The scatterplots we have seen so far investigated the relationship between two variables (features). A three-dimensional graph lets you introduce a third axis, typically called the _z_ axis, and can help you understand the relationship between three variables. Plotly's fully interactive functionality allows you to plot, hover, zoom and rotate 3-dimensional scatterplots. For a full list of arguments on 3d plots in Plotly visit https://plot.ly/python/reference/#scatter3d. Other examples on 3D scatterplots using Plotly can be found at https://plot.ly/python/3d-scatter-plots/.\n",
    "\n",
    "_Hint: Investigate the Scatter3d object from Plotly_\n",
    "\n",
    "_Axes in 3D Plotly plots work a bit differently than in 2D (axes are bound to a Scene object -- use help(Scene))._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a 3D scatterplot using the first three features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Activity: Try different combinations of f1 and f2 (in a grid/scatterplot matrix if you can).\n",
    "\n",
    "\n",
    "A scatterplot matrix shows a grid of scatterplots where each attribute is plotted against all other attributes. For example, try to create a scatterplot matrix of the first four features.\n",
    "You can find further information on how to create and customise subplots with Plotly at https://plot.ly/python/subplots/.\n",
    "\n",
    "_Hints: You may want to use nested loops that iterate through the rows and columns of the grid, and also import and make use of the_ `make_subplots()` _function from Plotly_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a grid plot of scatterplots using a combination of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Unsupervised Learning\n",
    "\n",
    "### Clustering with K-Means\n",
    "\n",
    "K-means clustering is a method for finding clusters and cluster centres in a set of unlabelled data. Intuitively, we might think of a cluster as comprising a group of data points whose inter-point distances are small compared with the distances to points outside of the cluster. Given an initial set of K centres, the K-means algorithm alternates the two steps:\n",
    "\n",
    "- for each centre we identify the subset of training points (its cluster) that is closer to it than any other centre;\n",
    "\n",
    "- the mean of each feature for the data points in each cluster are computed, and the corresponding vector of means becomes the new centre for that cluster.\n",
    "\n",
    "These two steps are iterated until the centres no longer move or the assignments no longer change. Then, a new point x can be assigned to the cluster of the closest prototype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Run K-Means with two features\n",
    "\n",
    "Isolate the features `mean_spent` and `max_spent` (remember to index and slice the correct columns of the X `numpy` array), then run the K-Means algorithm on the resulting dataset using K=2 and visualise the result.\n",
    "\n",
    "* KMeans is a class that generates a kmeans model with a number of clusters\n",
    "* the `.fit` method adapts the cluster centres\n",
    "* the `.predict` method can be used to determine how the trained model classifies data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply k-means with 2 cluster using a subset of the features (mean_spent and max_spent)\n",
    "# Remember to index and slice the correct columns of the X numpy array\n",
    "# Use the fitted model to predict what the cluster of each customer should be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it can be used to visualise the results of the 2-cluster model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise the clusters using a scatter plot (or scatterplot matrix if you wish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The separation between the two clusters is neat (the two clusters can be separated with a line). One cluster contains customers with a low spendings and the second with high spendings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Activity - Run K-Means with all the features\n",
    "Run K-Means using all the features available and visualise the result in the subspace created by `mean_spent` and `max_spent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapt the code to run KMeans with 2 clusters but using all features this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapt the visualisation code accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is now different. The first cluster contains customers with a maximum spending close to the minimum mean spending and the second contains customers with a maximum spending far from the minimum mean spending. This way can tell apart customers that could be willing to buy object that cost more than their average spending.\n",
    "\n",
    "***Question***: Why can't the clusters be separated with a line as before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning activity - Compare expenditure between clusters\n",
    "\n",
    "Select the feature `'mean_spent'` (or any feature of your choice) and compare the two clusters obtained above using them. Can you interpret the output of these commands? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare expenditure between clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity - Compare mean expediture with box plot\n",
    "\n",
    "Compare the distribution of the feature `mean_spent` in the two clusters using a box plotCan you relate the visualisation with the table above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a boxplot of the two clusters for 'mean_spent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity - Compare the mean expenditure distributions\n",
    "\n",
    "Use the function `create_distplot` from `FigureFactory` to show the\n",
    "distribution of the mean expenditure in both clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compare the mean expediture with a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we note:\n",
    "\n",
    "* Cluster 0 contains more customers.\n",
    "* Customers in cluster 1 spend more in average\n",
    "* There is more variability in the behaviour of the Customers in cluster 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Activity - Looking at the centroids\n",
    "\n",
    "Look at the centroids of the clusters `kmeans.cluster_centers_` and check the values of the centers in for the features `'mean_spent', 'max_spent'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity - Compute the silhouette score\n",
    "Compute the silhouette score of the clusters resuting from the application of K-Means.\n",
    "\n",
    "The Silhouette Coefficient is calculated using the mean intra-cluster distance (``a``) and the mean nearest-cluster distance (``b``) for each sample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a, b)``. It represents how similar a sample is to the samples in its own cluster compared to samples in other clusters.\n",
    "\n",
    "The best value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar.\n",
    "\n",
    "To compute it apply the `silhouette_score` function with arguments `customers` (the data) and `cluster_assignment` (how your model predicts the classification for the data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your code here to print the silhouette score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***K-Means, pro and cons***\n",
    "\n",
    "Pro\n",
    "- fast, if your dataset is big K-Means might be the only option\n",
    "- easy to understand\n",
    "- any unseen point can be assigned to the cluster with the closest mean to the point\n",
    "- many implementations available\n",
    "\n",
    "Cons\n",
    "- you need to guess the number of clusters\n",
    "- clusters can be only globular\n",
    "- the results depends on the initial choice of the means\n",
    "- all the points are assigned to a cluster, clusters are affected by noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: Decision Trees and Random Forests\n",
    "\n",
    "In this module, you will implement two popular and extremely powerful Machine Learning models - Decision Trees and Random Forests - using Python and scikit-learn. For every classification model built with scikit-learn, we will follow four main steps: 1) **Building or instantiating ** the classification model (using either default, pre-defined or optimised parameters), 2) **Training** the model, 3) **Testing** the model, and 4) **Performance evaluation** using various metrics to test its generalisation ability.  Thorough validation techniques will be applied throughout these steps as a means of ensuring real-world metrics and avoiding cases of overfitting (or underfitting). Finally, you will learn how to optimise the hyperparameters of a model as a way of boosting its overall performance. \n",
    "\n",
    "\n",
    "### Learning Activity: Split the data into training and test sets\n",
    "\n",
    "Training and testing a classification model on the same dataset is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data (poor generalisation). To use different datasets for training and testing, we need to split the online retail dataset into two disjoint sets: train and test (**Holdout method**) using the `train_test_split()` function. \n",
    "\n",
    "The `random_state` argument specifies a value for the seed of the random generator. By setting this seed to a particular value, each time the code is executed, the split between train and test datasets will be exactly the same. If this value is not specified, a different split will be performed each time since the random generator driving the split will be seeded by a pseudo-random number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `train_test_split()` consists of four arrays. _XTrain_ and _yTrain_ are the two arrays you use to train your model. _XTest_ and _yTest_ are the two arrays that you use to evaluate your model. By default, scikit-learn splits the data so that 25% of it is used for testing, but you can also specify the proportion of data you want to use for training and testing. You can check http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html on how to set this parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code here to explore Xtrain, ytrain etc.. \n",
    "#(eg: frequency of Y, head of X, dimensionality, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the frequency of `yTest`, you will see that 59 random samples of class 0 (non-returning customers) and 441 random samples of class 1 (returning customers) are included in the yTest set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity:  Decision Trees\n",
    "\n",
    "Decision Tree classifiers construct classification models in the form of a tree structure. A decision tree progressively splits the training set into smaller subsets. Each node of the tree represents a subset of the data. Once a new sample is presented to the data, it is classified according to the test condition generated for each node of the tree.\n",
    "\n",
    "Let us build a simple decision tree with 3 layers. (See [here](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for the documentation of the Decision Tree classifier.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the classification model using a pre-defined parameter\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Calculate validation metrics for your classifier\n",
    "\n",
    "In a classification task, once you have created your predictive model, you will need to evaluate it. Evaluation functions help you to do this by reporting the performance of the model through four main performance metrics: precision, recall and specificity for the different classes, and overall accuracy. To understand these metrics, it is useful to create a _confusion matrix_, which records all the true positive, true negative, false positive and false negative values.\n",
    "\n",
    "We can compute the confusion matrix for our classifier using the `confusion_matrix` function in the `metrics` module. The inputs are the `yTest` and `yPred`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the confusion matrix for your classifier using metrics.confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Because performance metrics are such an important step of model evaluation, scikit-learn offers a wrapper around these functions, `metrics.classification_report`, to facilitate their computation. It also offers the function `metrics.accuracy_score` that we tried before to compute the overall accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Report the metrics using metrics.classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Learning activity: Boundary visualisation of Decision Trees\n",
    "\n",
    "We can visualise the classification boundary created by the Random Forest using the `visplots.dtDecisionPlot` function. You can check the arguments passed in this function by using the `help` command. In addition to the mandatory arguments, the function `visplots.dtDecisionPlot` takes as optional arguments the ones from the `DecisionTreeClassifier` function, so you can have a look at the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the boundary of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity:  Random Forests\n",
    "\n",
    "The random forests model is an _ensemble method_ since it aggregates a group of decision trees into an [ensemble](http://scikit-learn.org/stable/modules/ensemble.html). Ensemble learning involves the combination of several models to solve a single prediction problem. It works by generating multiple classifiers/models which learn and make predictions independently. Those predictions are then combined into a single (mega) prediction that should be as good or better than the prediction made by any one classifer. Unlike single decision trees which are likely to suffer from high variance or high bias (depending on how they are tuned) Random Forests use averaging to find a natural balance between the two extremes. <br/> \n",
    "\n",
    "Let us start by building a simple Random Forest model which consists of 150 independently trained decision trees. For further details and examples on how to construct a Random Forest, see [here](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a Random Forest classifier with 150 decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Visualising the RF accuracy\n",
    "\n",
    "We can also investigate how the overall test accuracy gets influenced with the increase of `n_estimators` (decision trees) in our model. In order to do so, we can use the provided `rfAvgAcc` function from `visplots`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your code here to use the rfAvgAcc function\n",
    "# use help(rfAvgAcc) if needed to see what arguments it requires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Feature Importance \n",
    "\n",
    "Random forests allow you to compute a heuristic for determining how “important” a feature is in predicting a target. This heuristic measures the change in prediction accuracy if you take a given feature and permute (scramble) it across the datapoints in the training set. The more the accuracy drops when the feature is permuted, the more “important” we can conclude the feature is.\n",
    "\n",
    "We can use the `feature_importances_` attribute of the RF classifier to obtain the relative importance of each feature, which we can then visualise using a simple bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the importance of the features in a barplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Learning activity: Boundary visualisation of Random Forests\n",
    "\n",
    "We can visualise the classification boundary created by the Random Forest using the `visplots.rfDecisionPlot` function. You can check the arguments passed in this function by using the `help` command. In addition to the mandatory arguments, the function `visplots.rfDecisionPlot` takes as optional arguments the ones from the `RandomForestClassifier` function, so you can have a look at the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Plot the boundary of Random Forest using the rfDecisionPlot from the visplots module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Tuning Random Forests with grid search\n",
    "\n",
    "Random forests offer several parameters that can be tuned. In this case, parameters such as `n_estimators`, `max_features`, `max_depth` and `min_samples_leaf` can be some of the parameters to be optimised. The optimal choice for these parameters is highly *data-dependent*. Rather than trying one-by-one predefined values for each hyperparameter, we can automate this process. The scikit-learn library provides the grid search function [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html), which allows us to exhaustively search for the optimum combination of parameters by evaluating models trained with a particular algorithm with all provided parameter combinations. Further details and examples on grid search with scikit-learn can be found [here](http://scikit-learn.org/stable/modules/grid_search.html). You can use the `GridSearchCV` function with the validation technique of your choice (in this example, 10-fold cross-validation has been applied) to search for a parametisation of the RF algorithm that gives a more optimal model.\n",
    "\n",
    "As a first step, create a dictionary of allowed parameter ranges for `n_estimators` and `max_depth` (or include more of the parameters you would like to tune) and conduct a grid search with cross validation using the `GridSearchCV` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conduct a grid search with 5-fold cross-validation using the dictionary of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, parameter search uses overall accuracy (`sklearn.metrics.accuracy_score`) as a metric in classification. For some applications, other scoring functions and metrics are better suited (for example in _unbalanced classification_, the overall accuracy score may often be misleading). An alternative scoring function such as the ones provided at http://scikit-learn.org/stable/modules/model_evaluation.html can be specified via the `scoring` parameter in `GridSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Visualising the grid search results in a heatmap\n",
    "\n",
    "We can also graphically represent the results of the grid search using a heatmap. Here we plot the results when `n_estimatos` and `max_depth` vary while `max_features` is fixed to the best value found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a heatmap to visualise the results of the grid search with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Testing and evaluating the generalisation performance\n",
    "\n",
    "When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process (_XTest_). So, we are testing our independent _XTest_ dataset using the optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the classifier using the *optimal* parameters detected by grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `classification_report` from the `metrics` module and the `accuracy_score` to see how well the classifier is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Support Vector Machines\n",
    "\n",
    "Support Vector Machines (SVMs) attempt to build a decision boundary that accurately separates the samples of different classes by *maximising* the margin between them.\n",
    "\n",
    "### Learning Activity: Linear SVMs\n",
    "\n",
    "At first, let us build a linear SVM model using the _default_ value for the hypeparameter `C` (based on the scikit-learn documentation, the default case is `C = 1.0`). The regularisation `C` trades off misclassification of training examples against simplicity of the decision surface. A low `C` tolerates training misclassifications and allows softer margins, while for high `C` the misclassifications become more significant leading to hard-margin SVMs and potentially cases of overfitting.\n",
    "\n",
    "Thorough documentation on how to implement linear SVMs with scikit-learn can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a linear SVM classifier with the default hyperparameter C\n",
    "# (where C = 1.0; this argument is optional and could be omitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Activity: Boundary visualisation of linear SVMs\n",
    "\n",
    "We can visualise the classification boundary created by the linear SVM using the `visplots.svmDecisionPlot` function. You can check the arguments passed in this function by using the `help` command. In this case, you need to set the kernel to `linear`. In addition to the mandatory arguments, the function `visplots.svmDecisionPlot` takes as optional arguments the ones from the `SVC` function, so you can have a look at the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the svmDecisionPlot from the visplots module to see the boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Non-linear (RBF) SVMs\n",
    "\n",
    "In addition to the regularisation parameter `C`, which is common for all types of SVM, the gamma hyperparameter in the RBF kernel controls the nonlinearity of the SVM bounaries. The larger the gamma, the more nonlinear the boundaries surrounding individual samples. Lower values of gamma lead to broader, more linear boundaries. <br/>  \n",
    "\n",
    "At first, let us build an RBF SVM model (set the `kernel` parameter to `rbf`) using the default values for the hypeparameters `C` (`C=1.0`) and `gamma` (`gamma='auto'`). Thorough documentation on how to implement SVMs with scikit-learn can be found at http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build a non-linear (RBF) classifier using the default parameters for C and gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Activity: Apply class weights\n",
    "\n",
    "Repeat the previous activity, but this time also set the argument `class_weight` to `balanced`. If this argument is not given, all classes are supposed to have weight one. The `balanced` mode uses the values of _y_ to automatically adjust weights inversely proportional to class frequencies in the input data as `n_samples / (n_classes * np.bincount(y)) `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a non-linear (RBF) classifier using class_weight='balanced' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what do you observe? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Activity: Boundary visualisation of non-linear (RBF) SVMs\n",
    "\n",
    "\n",
    "1) Try to visualise the classification boundary created by the RBF SVM using the `visplots.svmDecisionPlot` function with the default parameters of `C` and `gamma`. You can check the arguments passed in this function by using the `help` command. Remember to set the correct kernel! <br/>\n",
    "2) Try different combinations of `C` and `gamma`, re-plot the boundaries and investigate how different values of the hyperparameters affect the separating hyperplane <br/>\n",
    "3) Apply `class_weight = 'balanced'` and visualise the boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualise the boundaries of the RBF kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Activity: Hyperparameter tuning for non-linear SVMs\n",
    "\n",
    "Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. \n",
    "Proper choice of `C` and `gamma` is critical for the performance of SVMs. Optimisation (tuning) of the hyperparameters can be achieved by applying a coarse tuning (often followed by a finer-tuning in the \"neighborhood\" of good parameters). *This may take a few minutes to run*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the parameters to be optimised and their values/ranges \n",
    "# Range for gamma and Cost hyperparameters \n",
    "# Apply GridSearchCV using 5-fold cross-validation to tune these parameters\n",
    "# Print the optimal parameters detected by GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Activity: Testing and evaluating the generalisation performance\n",
    "\n",
    "When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process (_XTest_). So, we are testing our independent _XTest_ dataset using the optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an SVM with an RBF kernel using the bestC and bestG\n",
    "# train it on XTrain, yTrain\n",
    "# predict XTest and compare with yTest using the \n",
    "# classification_report and accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Activity: Visualise the results of GridsearchCV in a heatmap \n",
    "\n",
    "Plot the results of the grid search using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bonus activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END OF DAY"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
