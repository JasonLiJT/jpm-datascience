<!DOCTYPE html>
<!-- saved from url=(0057)http://beta.cambridgespark.com/courses/jpm/04-module.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.4">
<title>Decision Trees and Random Forests</title>
<link rel="stylesheet" href="./04-Decision Trees and Random Forests_files/css">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
body{-webkit-font-smoothing:antialiased}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
body{tab-size:4}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
<style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
<body class="article"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>
<div id="header">
<h1>Decision Trees and Random Forests</h1>
</div>
<div id="content">
<div class="sect1">
<h2 id="_about_this_module">About this module</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a id="Decision_Trees"></a>Decision Trees are one of the most widely-used and popular classification techniques in Machine Learning.
<a id="Random_Forests"></a>Random forests belong to a class of Machine Learning methods called <a id="Ensemble_models"></a>"ensemble" methods,
where many models (in this case Decision Trees) are generated from the training data and fused together into an ensemble to make predictions.</p>
</div>
<div class="paragraph">
<p>By the end of this module, you will learn how to implement these two extremely powerful Machine Learning models using Python and scikit-learn.
For every classification model built with scikit-learn, you should follow four main steps:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><em>Building or instantiating</em> the classification model (using either default, pre-defined or optimised parameters),</p>
</li>
<li>
<p><em>Training</em> the model,</p>
</li>
<li>
<p><em>Testing</em> the model, and</p>
</li>
<li>
<p><em>Reporting metrics and evaluating</em> the performance and generalisation ability of the constructed model.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Validation techniques will be applied throughout these steps to avoid cases of overfitting (or underfitting). Finally, you will learn how to optimise the hyperparameters of a model as a way of boosting its overall performance.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_decision_trees">Decision Trees</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a id="Decision_Trees"></a>Decision Trees are one of the most widely-used and popular classification techniques in Machine Learning due to their</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Simplicity: not many parameters need to be tuned and thereâ€™s no need to normalise the data before using them.</p>
</li>
<li>
<p>Scalability: the classification process requires less operation than other classification models (such as KNN).</p>
</li>
<li>
<p>Interpretability: a decision tree is easy to visualise and interpret, and can provide valuable insights about the data.</p>
</li>
<li>
<p>Efficiency: decision trees can handle both numerical but also categorical data as well as missing values.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Decision Tree classifiers construct classification models in the form of a tree structure. A decision tree progressively splits the training set into smaller subsets. Each node of the tree represents a subset of the data.</p>
</div>
<div id="mod5_decisionTrees" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod5_dataparts.png" alt="datapartitioning" width="500">
</div>
<div class="title">Figure 1. Data partitioning and correspondent tree representation.</div>
</div>
<div class="paragraph">
<p>The final (decision) tree consists of three types of nodes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <em>root</em> node that has no incoming edges and zero or more outgoing edges.</p>
</li>
<li>
<p><em>Internal</em> nodes, each of which has exactly one incoming edge, and two or more outgoing edges.</p>
</li>
<li>
<p>Finally, <em>leaf</em> or <em>terminal</em> nodes, each of which has exactly one incoming edge and no outgoing edges. In a decision tree, each leaf node is assigned a class label.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Root and internal nodes contain feature test conditions to separate samples based on different characteristics and leaf nodes are linked to the final decision of the model. Once a new sample is presented to the model, it applies the test conditions while a leaf node is reached and the class linked to the leaf node is reported as result.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Basic ideas behind growing a tree</div>
<div class="ulist">
<ul>
<li>
<p>Each split in the data is made in order to minimise a misclassification metric
(gini impurity, information gain, variance reduction) and keep the number of class instances balanced between the regions.</p>
</li>
<li>
<p>Leaf nodes need to be as pure as possible, which means that all the samples at a leaf node need to belong mostly to the same class.</p>
</li>
<li>
<p>Nodes at the top should be impure, which means that all the samples at the top node need to represent samples of both classes.</p>
</li>
<li>
<p>As a result all the classes need to have similar chances to be selected (the <em>impurity</em> of the tree is minimised).</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2 activity">
<h3 id="_split_the_data_into_training_and_test_sets">Split the data into training and test sets</h3>
<div class="paragraph">
<p>Before we start with the actual model building process, we need to ensure the <em>generalisation ability</em> of our classifier (remember that <em>generalisation</em> is the capacity of a model to perform well on data that has not been used for the training phase).</p>
</div>
<div class="paragraph">
<p>Training and testing a classification model on the same dataset is <em>a methodological mistake</em>: a model that would just repeat the labels of the samples that it has just seen would overestimate the score and would fail to predict anything useful on yet-unseen data, leading to poor generalisation performance.</p>
</div>
<div class="paragraph">
<p>To use different datasets for training and testing, we need to split the online
retail dataset into two mutually exclusive datasets, the training set and the test set;
this validation approach is referred to as the <em>holdout method</em> and is depicted as follows:</p>
</div>
<div id="mod3_holdout" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod3_holdout.png" alt="Mod3Holdout" width="350">
</div>
<div class="title">Figure 2. Holdout approach (random split into two disjoint datasets, the train and test set).</div>
</div>
<div class="paragraph">
<p>In Python, you need to use the <code>train_test_split()</code> function available through <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html">sklearn.cross_validation</a>. The function takes two mandatory arguments, which are the matrix <em>X</em> holding the input data and the vector <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-1" role="math" style="width: 0.524em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.429em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.995em 1000.43em 2.896em -999.998em); top: -2.559em; left: 0.002em;"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3" style="font-family: STIXGeneral-Italic;">y</span></span><span style="display: inline-block; width: 0px; height: 2.564em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.291em; border-left: 0px solid; width: 0px; height: 0.944em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi></math></span></span><script type="math/tex" id="MathJax-Element-1">y</script> holding the targets (class labels).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Split into training and test sets</span><span class="pln">

</span><span class="typ">XTrain</span><span class="pun">,</span><span class="pln"> </span><span class="typ">XTest</span><span class="pun">,</span><span class="pln"> yTrain</span><span class="pun">,</span><span class="pln"> yTest </span><span class="pun">=</span><span class="pln"> train_test_split</span><span class="pun">(</span><span class="pln">X</span><span class="pun">,</span><span class="pln"> y</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">1</span><span class="pun">)</span><span class="pln"> </span><b class="conum"><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>The <code>random_state</code> argument specifies a value for the seed of the random generator. By setting this seed to a particular value, each time the code is run, the split between train and test datasets will be exactly the same. If this value is not specified, a different split will be output each time since the random generator driving the split will be seeded by a pseudo-random number.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The output of <code>train_test_split</code> consists of four arrays.
<em>XTrain</em> and <em>yTrain</em> are the two arrays you use to train your model.
<em>XTest</em> and <em>yTest</em> are the two arrays that you use to evaluate your model.
By default, scikit-learn splits the data so that 25% of it is used for testing, but you can also specify the proportion of data you want to use for training and testing.</p>
</div>
<div class="paragraph">
<p>As previously, you can check the sizes of the different training and test sets by using the <code>shape</code> attribute:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Print the dimensionality of the individual splits</span><span class="pln">

</span><span class="kwd">print</span><span class="pun">(</span><span class="str">"XTrain dimensions: "</span><span class="pun">,</span><span class="pln"> </span><span class="typ">XTrain</span><span class="pun">.</span><span class="pln">shape</span><span class="pun">)</span><span class="pln">
</span><span class="kwd">print</span><span class="pun">(</span><span class="str">"yTrain dimensions: "</span><span class="pun">,</span><span class="pln"> yTrain</span><span class="pun">.</span><span class="pln">shape</span><span class="pun">)</span><span class="pln">
</span><span class="kwd">print</span><span class="pun">(</span><span class="str">"XTest dimensions: "</span><span class="pun">,</span><span class="pln">  </span><span class="typ">XTest</span><span class="pun">.</span><span class="pln">shape</span><span class="pun">)</span><span class="pln">
</span><span class="kwd">print</span><span class="pun">(</span><span class="str">"yTest dimensions: "</span><span class="pun">,</span><span class="pln">  yTest</span><span class="pun">.</span><span class="pln">shape</span><span class="pun">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This results in the following output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="pun">&gt;</span><span class="pln"> </span><span class="typ">XTrain</span><span class="pln"> dimensions</span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="lit">1498</span><span class="pun">,</span><span class="pln"> </span><span class="lit">10</span><span class="pun">)</span><span class="pln">
</span><span class="pun">&gt;</span><span class="pln"> yTrain dimensions</span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="lit">1498</span><span class="pun">,</span><span class="pln"> </span><span class="pun">)</span><span class="pln">
</span><span class="pun">&gt;</span><span class="pln"> </span><span class="typ">XTest</span><span class="pln"> dimensions</span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="lit">500</span><span class="pun">,</span><span class="pln"> </span><span class="lit">10</span><span class="pun">)</span><span class="pln">
</span><span class="pun">&gt;</span><span class="pln"> yTest dimensions</span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="lit">500</span><span class="pun">,</span><span class="pln"> </span><span class="pun">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also investigate how the class labels are distributed within the <em>yTest</em> vector by using the <code>itemfreq</code> function from module 2:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Calculate the frequency of classes in yTest</span><span class="pln">

yFreq </span><span class="pun">=</span><span class="pln"> scipy</span><span class="pun">.</span><span class="pln">stats</span><span class="pun">.</span><span class="pln">itemfreq</span><span class="pun">(</span><span class="pln">yTest</span><span class="pun">)</span><span class="pln">
</span><span class="kwd">print</span><span class="pun">(</span><span class="pln">yFreq</span><span class="pun">)</span><span class="pln">
</span><span class="pun">&gt;</span><span class="pln"> </span><span class="pun">[[</span><span class="pln">  </span><span class="lit">0</span><span class="pln"> </span><span class="lit">59</span><span class="pun">]</span><span class="pln">
   </span><span class="pun">[</span><span class="pln">  </span><span class="lit">1</span><span class="pln"> </span><span class="lit">441</span><span class="pun">]]</span><span class="pln"> </span><b class="conum"><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>In this case, we can see that <em>yTest</em> includes 59 random samples of class 0 (non-returning customers)
and 441 random samples of class 1 (returning customers).</p>
</li>
</ol>
</div>
</div>
<div class="sect2 activity">
<h3 id="_building_a_decision_tree">Building a Decision Tree</h3>
<div class="paragraph">
<p>Decision Tree classifiers construct classification models in the form of a tree structure. A decision tree progressively splits the training set into smaller subsets. Each node of the tree represents a subset of the data. Once a new sample is presented, it is classified according to the test condition generated for each node of the tree.</p>
</div>
<div class="paragraph">
<p>Try building a simple decision tree with 3 layers (See <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">Decision Tree documentation</a> for the arguments that can be passed to the classifier).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Building the classification model using a pre-defined parameter</span><span class="pln">
dtc </span><span class="pun">=</span><span class="pln"> </span><span class="typ">DecisionTreeClassifier</span><span class="pun">(</span><span class="pln">max_depth</span><span class="pun">=</span><span class="lit">3</span><span class="pun">)</span><span class="pln"> </span><b class="conum"><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></b><span class="pln">

</span><span class="com"># Train the model</span><span class="pln">
dtc</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="typ">XTrain</span><span class="pun">,</span><span class="pln"> yTrain</span><span class="pun">)</span><span class="pln">

</span><span class="com"># Test the model</span><span class="pln">
yPred </span><span class="pun">=</span><span class="pln"> dtc</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="typ">XTest</span><span class="pun">)</span></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Setting the parameter <code>max_depth</code> to 3 we stipulate that the decision tree will have no more than 3 links from the root node to the leaves.</p>
</li>
</ol>
</div>
</div>
<div class="sect2 activity">
<h3 id="_calculate_validation_metrics_for_your_classifier">Calculate validation metrics for your classifier</h3>
<div class="paragraph">
<p>In a classification task, once you have created your predictive model, you will always need to evaluate it. Evaluation functions help you to do this by reporting the performance of the model through four main performance metrics:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>precision,</p>
</li>
<li>
<p>sensitivity (or recall, true positive rate),</p>
</li>
<li>
<p>specificity (or true negative rate), and</p>
</li>
<li>
<p>overall accuracy.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>As opposed to overall classification accuracy, the first three metrics are class-specific: they may differ for the two classes, whereas the overall accuracy may remain the same. To understand these metrics, it is useful to create a <em>confusion matrix</em>, which records all the true positive, true negative, false positive and false negative values.</p>
</div>
<div class="paragraph">
<p>We can compute the confusion matrix for our classifier using the <code>confusion_matrix</code> function in the <code>metrics</code> module.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Get the confusion matrix for your classifier using metrics.confusion_matrix</span><span class="pln">

mat </span><span class="pun">=</span><span class="pln"> metrics</span><span class="pun">.</span><span class="pln">confusion_matrix</span><span class="pun">(</span><span class="pln">yTest</span><span class="pun">,</span><span class="pln"> yPred</span><span class="pun">)</span><span class="pln">  </span><b class="conum"><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></b><span class="pln">
</span><span class="kwd">print</span><span class="pln"> </span><span class="pun">(</span><span class="pln">mat</span><span class="pun">)</span><span class="pln">

</span><span class="pun">&gt;</span><span class="pln">   </span><span class="pun">[[</span><span class="pln"> </span><span class="lit">32</span><span class="pln">  </span><span class="lit">27</span><span class="pun">]</span><span class="pln">
     </span><span class="pun">[</span><span class="pln"> </span><span class="lit">19</span><span class="pln"> </span><span class="lit">422</span><span class="pun">]]</span><span class="pln">  </span><b class="conum"><span class="pun">(</span><span class="lit">2</span><span class="pun">)</span></b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>Compute the confusion matrix for our predictions. Remember that the test data contain observations that are <strong>not</strong> in the training data.</p>
</li>
<li>
<p>The first value in the first row (32) is the number of True Positives (TP);
the second value in the first row (27) is the number of False Negatives (FN);
the first value in the second row (19)  is the number of False Positives (FP),
and the second value in the second row (422) is the number of True Negatives (TN). We could represent this schematically as follows:</p>
</li>
</ol>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title"><a id="Error_rate"></a>Validation Metrics</div>
<div class="ulist">
<ul>
<li>
<p><a id="Accuracy"></a><strong>Accuracy:</strong> Accuracy is the overall "correctness" of the model and is calculated as the number of correctly classified observations divided by the total number of observations. Accuracy is defined by</p>
<div class="paragraph">
<p><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;/mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4" role="math" style="width: 13.158em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.587em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.666em 1010.59em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-5"><span class="mi" id="MathJax-Span-6" style="font-family: STIXGeneral-Italic;">A</span><span class="mi" id="MathJax-Span-7" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-8" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-9" style="font-family: STIXGeneral-Italic;">u</span><span class="mi" id="MathJax-Span-10" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-11" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-12" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-13" style="font-family: STIXGeneral-Italic;">y</span><span class="mo" id="MathJax-Span-14" style="font-family: STIXGeneral-Regular; padding-left: 0.305em;">=</span><span class="mo" id="MathJax-Span-15" style="font-family: STIXGeneral-Regular; padding-left: 0.305em;">(</span><span class="mi" id="MathJax-Span-16" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-17" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-18" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">+</span><span class="mi" id="MathJax-Span-19" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-20" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-21" style="font-family: STIXGeneral-Regular;">)</span><span class="texatom" id="MathJax-Span-22"><span class="mrow" id="MathJax-Span-23"><span class="mo" id="MathJax-Span-24" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mi" id="MathJax-Span-25" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-26" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-27" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-28" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-29" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mo stretchy="false">(</mo><mi>t</mi><mi>p</mi><mo>+</mo><mi>t</mi><mi>n</mi><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></math></span></span><script type="math/tex" id="MathJax-Element-2"> Accuracy = (tp+tn)/total </script></p>
</div>
<div class="paragraph">
<p>where <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-30" role="math" style="width: 1.011em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.809em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.817em 1000.76em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-31"><span class="mi" id="MathJax-Span-32" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-33" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.066em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> tp </script> and <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-34" role="math" style="width: 0.96em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.759em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.817em 1000.71em 2.674em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-35"><span class="mi" id="MathJax-Span-36" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-37" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-4"> tn </script> are the numbers of true positive and true negative predictions and total is the total number of instances.</p>
</div>
</li>
<li>
<p><a id="Precision"></a><strong>Precision (for a class):</strong> Precision is a measure of the accuracy for a specific class, it reports the proportion of correct classifications for a specific class. It is defined by:</p>
<div class="paragraph">
<p><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-38" role="math" style="width: 12.099em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.73em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.716em 1009.68em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-39"><span class="mi" id="MathJax-Span-40" style="font-family: STIXGeneral-Italic;">P</span><span class="mi" id="MathJax-Span-41" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-42" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-43" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-44" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-45" style="font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-46" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-47" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-48" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-49" style="font-family: STIXGeneral-Regular; padding-left: 0.305em;">=</span><span class="mi" id="MathJax-Span-50" style="font-family: STIXGeneral-Italic; padding-left: 0.305em;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-51" style="font-family: STIXGeneral-Italic;">p</span><span class="texatom" id="MathJax-Span-52"><span class="mrow" id="MathJax-Span-53"><span class="mo" id="MathJax-Span-54" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mo" id="MathJax-Span-55" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-56" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-57" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-58" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">+</span><span class="mi" id="MathJax-Span-59" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-60" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-61" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mi>t</mi><mi>p</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mo stretchy="false">(</mo><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>p</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-5"> Precision = tp/(tp + fp) </script></p>
</div>
<div class="paragraph">
<p>where <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-62" role="math" style="width: 1.011em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.809em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.817em 1000.76em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-63"><span class="mi" id="MathJax-Span-64" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-65" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.066em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-6"> tp </script> and <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-66" role="math" style="width: 1.212em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.96em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.716em 1000.91em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-67"><span class="mi" id="MathJax-Span-68" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-69" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-7"> fp </script> are the numbers of true positive and false positive predictions for the considered class, e.g. ability to correctly classify a customer as being returning or non-returning. <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-70" role="math" style="width: 3.632em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.926em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.716em 1002.88em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-71"><span class="mi" id="MathJax-Span-72" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-73" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-74" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">+</span><span class="mi" id="MathJax-Span-75" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-76" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-8"> tp + fp </script> is the total number of elements labelled as belonging to the considered class by the classifier.</p>
</div>
</li>
<li>
<p><a id="Recall"></a><strong>Recall, aka. <a id="Sensitivity"></a>Sensitivity, <a id="True_Positive_Rate"></a>True positive rate (for a class):</strong> Recall reports the ability of a model to select instances of a certain class from a dataset, e.g. a classifier that has high sensitivity with regards to the non-returning class will do well at correctly classifying customers as being non-returning (although this may make it more likely to incorrectly include more returning customers in this class). It is defined by:</p>
<div class="paragraph">
<p><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;R&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;v&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-77" role="math" style="width: 17.19em; display: inline-block;"><span style="display: inline-block; position: relative; width: 13.863em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.666em 1013.81em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-78"><span class="mi" id="MathJax-Span-79" style="font-family: STIXGeneral-Italic;">R</span><span class="mi" id="MathJax-Span-80" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-81" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-82" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-83" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-84" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-85" style="font-family: STIXGeneral-Regular; padding-left: 0.305em;">=</span><span class="mi" id="MathJax-Span-86" style="font-family: STIXGeneral-Italic; padding-left: 0.305em;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-87" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-88" style="font-family: STIXGeneral-Italic;">n</span><span class="mi" id="MathJax-Span-89" style="font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-90" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-91" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-92" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-93" style="font-family: STIXGeneral-Italic;">v</span><span class="mi" id="MathJax-Span-94" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-95" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-96" style="font-family: STIXGeneral-Italic;">y</span><span class="mo" id="MathJax-Span-97" style="font-family: STIXGeneral-Regular; padding-left: 0.305em;">=</span><span class="mi" id="MathJax-Span-98" style="font-family: STIXGeneral-Italic; padding-left: 0.305em;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-99" style="font-family: STIXGeneral-Italic;">p</span><span class="texatom" id="MathJax-Span-100"><span class="mrow" id="MathJax-Span-101"><span class="mo" id="MathJax-Span-102" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mo" id="MathJax-Span-103" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-104" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-105" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-106" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">+</span><span class="mi" id="MathJax-Span-107" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-108" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-109" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mi>S</mi><mi>e</mi><mi>n</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mi>t</mi><mi>p</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mo stretchy="false">(</mo><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-9"> Recall = Sensitivity = tp/(tp + fn) </script></p>
</div>
<div class="paragraph">
<p>where <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-110" role="math" style="width: 1.011em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.809em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.817em 1000.76em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-111"><span class="mi" id="MathJax-Span-112" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-113" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.066em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-10"> tp </script> and <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-114" role="math" style="width: 1.162em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.91em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.716em 1000.86em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-115"><span class="mi" id="MathJax-Span-116" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-117" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-11"> fn </script> are the numbers of true positive and false negative predictions for the considered class. <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-118" role="math" style="width: 3.632em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.926em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.716em 1002.88em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-119"><span class="mi" id="MathJax-Span-120" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-121" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-122" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">+</span><span class="mi" id="MathJax-Span-123" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-124" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-12"> tp + fn </script> is the total number of elements that actually belong to the considered class.</p>
</div>
</li>
<li>
<p><a id="Specificity"></a><strong>Specificity, <a id="True_Negative_Rate"></a>True negative rate (for a class):</strong> Specificity reports the ability of the model to correctly exclude class non-members in a dataset from the class, e.g. a classifier that has high specificity wrt the non-returning class will do well at correctly excluding returning customers from the class (although this may make it more likely to miss non-returning customers). It is defined by:</p>
<div class="paragraph">
<p><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-125" role="math" style="width: 12.704em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.234em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.716em 1010.18em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-126"><span class="mi" id="MathJax-Span-127" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-128" style="font-family: STIXGeneral-Italic;">p</span><span class="mi" id="MathJax-Span-129" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-130" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-131" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-132" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-133" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-134" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-135" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-136" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-137" style="font-family: STIXGeneral-Italic;">y</span><span class="mo" id="MathJax-Span-138" style="font-family: STIXGeneral-Regular; padding-left: 0.305em;">=</span><span class="mi" id="MathJax-Span-139" style="font-family: STIXGeneral-Italic; padding-left: 0.305em;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-140" style="font-family: STIXGeneral-Italic;">n</span><span class="texatom" id="MathJax-Span-141"><span class="mrow" id="MathJax-Span-142"><span class="mo" id="MathJax-Span-143" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mo" id="MathJax-Span-144" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-145" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-146" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-147" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">+</span><span class="mi" id="MathJax-Span-148" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-149" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-150" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi><mi>p</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>f</mi><mi>i</mi><mi>c</mi><mi>i</mi><mi>t</mi><mi>y</mi><mo>=</mo><mi>t</mi><mi>n</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mo stretchy="false">(</mo><mi>f</mi><mi>p</mi><mo>+</mo><mi>t</mi><mi>n</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-13"> Specificity = tn/(fp + tn) </script></p>
</div>
<div class="paragraph">
<p>where <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-151" role="math" style="width: 0.96em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.759em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.817em 1000.71em 2.674em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-152"><span class="mi" id="MathJax-Span-153" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-154" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.059em; border-left: 0px solid; width: 0px; height: 0.816em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-14"> tn </script> and <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-155" role="math" style="width: 1.212em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.96em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.716em 1000.91em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-156"><span class="mi" id="MathJax-Span-157" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-158" style="font-family: STIXGeneral-Italic;">p</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-15"> fp </script> are the numbers of true negative and false positive predictions for the considered class.  <span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-159" role="math" style="width: 3.632em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.926em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.716em 1002.88em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-160"><span class="mi" id="MathJax-Span-161" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.154em;"></span></span><span class="mi" id="MathJax-Span-162" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-163" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">+</span><span class="mi" id="MathJax-Span-164" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-165" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mi>p</mi><mo>+</mo><mi>t</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-16"> fp + tn </script> is the total number of elements that should not be included in the class.</p>
</div>
</li>
<li>
<p><a id="F1"></a><strong>F1-score (for a class):</strong> This measures the accuracy of the model with respect to a particular class, and is the harmonic mean of precision and recall. It is defined by:</p>
<div class="paragraph">
<p><span class="MathJax_Preview" style="color: inherit;"></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mi&gt;F&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;&amp;#x2217;&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;&amp;#x2217;&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;/mrow&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-166" role="math" style="width: 24.7em; display: inline-block;"><span style="display: inline-block; position: relative; width: 19.912em; height: 0px; font-size: 124%;"><span style="position: absolute; clip: rect(1.666em 1019.86em 2.876em -999.997em); top: -2.518em; left: 0.003em;"><span class="mrow" id="MathJax-Span-167"><span class="mi" id="MathJax-Span-168" style="font-family: STIXGeneral-Italic;">F<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.053em;"></span></span><span class="mn" id="MathJax-Span-169" style="font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-170" style="font-family: STIXGeneral-Regular; padding-left: 0.305em;">=</span><span class="mn" id="MathJax-Span-171" style="font-family: STIXGeneral-Regular; padding-left: 0.305em;">2</span><span class="mo" id="MathJax-Span-172" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">âˆ—</span><span class="mo" id="MathJax-Span-173" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">(</span><span class="mi" id="MathJax-Span-174" style="font-family: STIXGeneral-Italic;">p</span><span class="mi" id="MathJax-Span-175" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-176" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-177" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-178" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-179" style="font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-180" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-181" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-182" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-183" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">âˆ—</span><span class="mi" id="MathJax-Span-184" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-185" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-186" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-187" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-188" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-189" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-190" style="font-family: STIXGeneral-Regular;">)</span><span class="texatom" id="MathJax-Span-191"><span class="mrow" id="MathJax-Span-192"><span class="mo" id="MathJax-Span-193" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mo" id="MathJax-Span-194" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-195" style="font-family: STIXGeneral-Italic;">p</span><span class="mi" id="MathJax-Span-196" style="font-family: STIXGeneral-Italic;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-197" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-198" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-199" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-200" style="font-family: STIXGeneral-Italic;">s</span><span class="mi" id="MathJax-Span-201" style="font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-202" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-203" style="font-family: STIXGeneral-Italic;">n</span><span class="mo" id="MathJax-Span-204" style="font-family: STIXGeneral-Regular; padding-left: 0.255em;">+</span><span class="mi" id="MathJax-Span-205" style="font-family: STIXGeneral-Italic; padding-left: 0.255em;">r<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-206" style="font-family: STIXGeneral-Italic;">e</span><span class="mi" id="MathJax-Span-207" style="font-family: STIXGeneral-Italic;">c</span><span class="mi" id="MathJax-Span-208" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-209" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-210" style="font-family: STIXGeneral-Italic;">l<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-211" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.523em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.309em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>F</mi><mn>1</mn><mo>=</mo><mn>2</mn><mo>âˆ—</mo><mo stretchy="false">(</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>âˆ—</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo stretchy="false">)</mo><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mo stretchy="false">(</mo><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-17"> F1 = 2 * (precision * recall)/(precision + recall) </script></p>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>Because performance metrics are such an important step of model evaluation,
scikit-learn offers a wrapper around these functions, <code>metrics.classification_report</code>,
to facilitate their computation. It also offers the function <code>metrics.accuracy_score</code> to compute the overall accuracy.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Report the metrics using metrics.classification_report</span><span class="pln">

</span><span class="kwd">print</span><span class="pln"> </span><span class="pun">(</span><span class="pln">metrics</span><span class="pun">.</span><span class="pln">classification_report</span><span class="pun">(</span><span class="pln">yTest</span><span class="pun">,</span><span class="pln"> yPred</span><span class="pun">))</span><span class="pln">
</span><span class="kwd">print</span><span class="pln"> </span><span class="pun">(</span><span class="str">"Overall Accuracy: "</span><span class="pun">,</span><span class="pln"> round</span><span class="pun">(</span><span class="pln">metrics</span><span class="pun">.</span><span class="pln">accuracy_score</span><span class="pun">(</span><span class="pln">yTest</span><span class="pun">,</span><span class="pln"> yPred</span><span class="pun">),</span><span class="pln"> </span><span class="lit">2</span><span class="pun">))</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The performance summary and accuracy will be as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="pln">                precision    recall  f1</span><span class="pun">-</span><span class="pln">score   support

</span><span class="lit">0</span><span class="pln">                 </span><span class="lit">0.63</span><span class="pln">      </span><span class="lit">0.54</span><span class="pln">      </span><span class="lit">0.58</span><span class="pln">        </span><span class="lit">59</span><span class="pln">
</span><span class="lit">1</span><span class="pln">                 </span><span class="lit">0.94</span><span class="pln">      </span><span class="lit">0.96</span><span class="pln">      </span><span class="lit">0.95</span><span class="pln">       </span><span class="lit">441</span><span class="pln">

avg </span><span class="pun">/</span><span class="pln"> total       </span><span class="lit">0.90</span><span class="pln">      </span><span class="lit">0.91</span><span class="pln">      </span><span class="lit">0.91</span><span class="pln">       </span><span class="lit">500</span><span class="pln">

</span><span class="typ">Overall</span><span class="pln"> </span><span class="typ">Accuracy</span><span class="pun">:</span><span class="pln">  </span><span class="lit">0.91</span></code></pre>
</div>
</div>
</div>
<div class="sect2 activity">
<h3 id="_boundary_visualisation_of_decision_trees">Boundary visualisation of Decision Trees</h3>
<div class="paragraph">
<p>The border between two neighboring regions of different classes is known as the <em>decision boundary</em>.
We have provided you with a pre-defined function in the <code>visplots</code> library called <code>dtDecisionPlot</code> that allows you to do this.
You can check the arguments passed in this function by using the <code>help</code> command.
In addition to the mandatory arguments, the function <code>visplots.dtDecisionPlot</code> takes as optional arguments the ones from the <code>DecisionTreeClassifier</code> function,
so you can have a look at the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier">documentation</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com">#### Check the arguments of the function</span><span class="pln">
help</span><span class="pun">(</span><span class="pln">visplots</span><span class="pun">.</span><span class="pln">dtDecisionPlot</span><span class="pun">)</span><span class="pln">

</span><span class="com"># Plot the boundary of Decision Trees</span><span class="pln">
visplots</span><span class="pun">.</span><span class="pln">dtDecisionPlot</span><span class="pun">(</span><span class="typ">XTrain</span><span class="pun">,</span><span class="pln"> yTrain</span><span class="pun">,</span><span class="pln"> </span><span class="typ">XTest</span><span class="pun">,</span><span class="pln"> yTest</span><span class="pun">,</span><span class="pln"> header</span><span class="pun">,</span><span class="pln"> max_depth </span><span class="pun">=</span><span class="pln"> </span><span class="lit">3</span><span class="pun">)</span></code></pre>
</div>
</div>
<div id="mod3_treeBoundary" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod4_plotly_dtBoundary.png" alt="Decision Tree Performance" width="540">
</div>
<div class="title">Figure 3. Decision Boundary of a Tree with max depth 3.</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Boundary interpretation</div>
<div class="paragraph">
<p>The decision region for a decision tree is rectilinear ("stair-like" or "box-like" surfaces) with segments parallel to the input axes since each test condition involves only a single attribute.
In this case, the boundary defines a decision region for each class.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>The more splits are performed the more detailed the model becomes (the deeper the tree). Despite the power and simplicity of this algorithm, decision-tree learners have three main drawbacks:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>They can be very unstable as they are sensitive to small changes in the training data: a small change can lead to a totally different tree (high variance).</p>
</li>
<li>
<p>They can easily <em>overfit</em>. Decision-tree learners can create over-complex trees that do not generalise the data well.</p>
</li>
<li>
<p>Their decision boundary is non-smooth.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_bias_variance_trade_off">Bias-variance trade-off</h2>
<div class="sectionbody">
<div class="paragraph">
<p>One of the fundamental concepts of Machine Learning is that of <a id="Overfitting"></a>overfitting and <a id="Generalisation"></a>generalisation.</p>
</div>
<div class="paragraph">
<p>When a trained model performs extremely well on the training dataset, but fails to predict new unseen data, the model is sufferning from the effect of <em>high variance</em>.
This situation is called <em>overfitting</em>, leading to poor generalisation performance.</p>
</div>
<div class="paragraph">
<p>Similarly, a model might be too "simple", unable to capture the true relationship in the data that we observe.
These models would be said to have <em>high bias</em>; they do not fit the data very well,
which leads to a high generalisation error on new test data. This situation is called <em>underfitting</em>.</p>
</div>
<div class="paragraph">
<p>There is a fundamental trade-off between model complexity and the possibility of high <a id="Bias"></a>bias or high <a id="Variance"></a>variance
for all Machine Learning algorithms. Such an example is presented in <a href="http://beta.cambridgespark.com/courses/jpm/mod3_bias_variance">Figure 3-4</a>. We can see from this picture that initially both the training and test <em>error</em> are quite high (hence the <em>accuracy</em> will be low) as the model is too simplistic and thus unable to learn and predict the data accurately (case of under-fitting).
However, as the boundaries become more and more complex, capturing noise in the data, the test error tends to increase while the training error steadily decreases; this is a case of overfitting.</p>
</div>
<div class="paragraph">
<p>The main task during the optimisation of any Machine Learning model is to find the optimal "sweet spot" where the model minimises simultaneously both the bias and the variance. One very powerful tool at our disposal is <em>validation</em>. It is a common approach used to help us to detect and avoid cases of over- and underfitting.</p>
</div>
<div id="mod3_bias_variance" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod3_bias_variance.png" alt="width=1.1in">
</div>
<div class="title">Figure 4. Classification: over-fitting vs under-fitting.</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Figure Interpretation</div>
<div class="paragraph">
<p>The green lines across the panel represent different models (Model 1-3) that have been trained on a dataset (top row). The prediction errors are recorded below each panel. From left to right, the models have increasing complexity. At first glance Model 3 seems perfect with a prediction error of 0. However when submitting new data (test data - second row) to this model it soon becomes apparent that this model does not perform well anymore. This is referred to as overfitting. On the other end of the spectrum, Model 1 is too simple and does not capture the relationship that is being classified. For both the training and test data it performs poorly (underfitting). Model 2 strikes the right balance, it has a low prediction error and is generalisable.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>A thorough tutorial on misleading modelling, overfitting, cross-validation, and the bias-variance trade-off can be found <a href="http://online.cambridgecoding.com/notebooks/cca_admin/misleading-modelling-overfitting-crossvalidation-and-the-biasvariance-tradeoff">here</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ensemble_models">Ensemble models</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ensemble learning (or modelling) involves the combination of several <em>accurate</em> and <em>diverse</em> models to solve a single
prediction problem. It works by generating multiple models, which learn and make predictions independently. Those predictions are then combined
into a single (mega) prediction that should be as good or better than the prediction made by any one classifer.
An ensemble is itself a <em>supervised learning</em> problem as it can be trained and used to make predictions.</p>
</div>
<div class="paragraph">
<p>There are two main families of ensemble methods:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><em>Averaging methods</em>: where several estimators are being built independently and
then their predictions are averaged or combined by a voting scheme.
Averaging methods attempt to reduce the <em>variance</em> of the single base estimators.
Examples include: Bagging methods and Forests of randomised trees, among others.</p>
</li>
<li>
<p><em>Boosting methods</em>: in this ensemble model, base estimators are built sequentially
with the motivation is to combine several weak models to produce a powerful ensemble.
Boosting methods attempt to reduce the <em>bias</em> of the combined estimator.
Examples include AdaBoost and Gradient Tree Boosting, among others.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_random_forests">Random Forests</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The random forests model is an <em>ensemble method</em> since it aggregates a group of
decision trees into an <a href="http://scikit-learn.org/stable/modules/ensemble.html">ensemble</a>.
Unlike single decision trees which are likely to suffer
from high variance or high bias (depending on how they are tuned) Random Forests
use averaging to find a natural balance between the two extremes.</p>
</div>
<div class="paragraph">
<p>A forest of uncorrelated trees is being built using a CART like procedure,
combined with randomised node optimisation and <a id="Bagging"></a>"bagging" (<a id="Bootstrap_aggregating"></a>bootstrap aggregating).
Bagging helps reduce variance, improve unstable procedures and avoid overfitting.
So, for each tree to learn we:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Subsample the data randomly <em>with replacement</em>.</p>
</li>
<li>
<p>Select a subset of the original features.</p>
</li>
<li>
<p>Apply the learning procedure only to the subsample drawn and the features selected.</p>
</li>
<li>
<p>Once many models are generated, their predictions can be combined into a single (mega) prediction using <em>majority vote or averaging</em> that should be better, on average, than the prediction made by the single models.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The percentage of data to grow each tree is arbitrary, but a widely used choice is 63% (.632 rule).</p>
</div>
<div id="mod3_bootstrap" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod5_bootstrap.png" alt="Bootstrap example">
</div>
<div class="title">Figure 5. Example of how bootstrap works when applied to decision trees.</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Boosting</div>
<div class="paragraph">
<p>Bagging is not the only option to create an ensemble of trees, a very popular alternative is <a id="Boosting"></a>Boosting. Boosting doesnâ€™t subsample the data, it uses the entire dataset multiple times giving to samples which are hard to classify an increasing importance. This strategy also assigns a different importance to each tree which is used to weigh their vote during the classification.</p>
</div>
</div>
</div>
<div class="sect2 activity">
<h3 id="_building_a_random_forest">Building a Random Forest</h3>
<div class="paragraph">
<p>Start by building a simple Random Forest model, which consists of 150 independently trained decision trees, using the <code>RandomForestClassifier</code> function.
For further details and examples on how to construct a Random Forest, see the help page of <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"><code>RandomForestClassifier</code></a></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Build a Random Forest classifier with 150 decision trees</span><span class="pln">

rf </span><span class="pun">=</span><span class="pln"> </span><span class="typ">RandomForestClassifier</span><span class="pun">(</span><span class="pln">n_estimators</span><span class="pun">=</span><span class="lit">150</span><span class="pun">,</span><span class="pln"> random_state</span><span class="pun">=</span><span class="lit">1</span><span class="pun">)</span><span class="pln"> </span><b class="conum"><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></b><span class="pln">
rf</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="typ">XTrain</span><span class="pun">,</span><span class="pln"> yTrain</span><span class="pun">)</span><span class="pln">
predRF </span><span class="pun">=</span><span class="pln"> rf</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="typ">XTest</span><span class="pun">)</span><span class="pln">

</span><span class="kwd">print</span><span class="pun">(</span><span class="pln">metrics</span><span class="pun">.</span><span class="pln">classification_report</span><span class="pun">(</span><span class="pln">yTest</span><span class="pun">,</span><span class="pln"> predRF</span><span class="pun">))</span><span class="pln">
</span><span class="kwd">print</span><span class="pun">(</span><span class="str">"Overall Accuracy:"</span><span class="pun">,</span><span class="pln"> round</span><span class="pun">(</span><span class="pln">metrics</span><span class="pun">.</span><span class="pln">accuracy_score</span><span class="pun">(</span><span class="pln">yTest</span><span class="pun">,</span><span class="pln"> predRF</span><span class="pun">),</span><span class="lit">2</span><span class="pun">))</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This results in the following output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="pln">                precision    recall  f1</span><span class="pun">-</span><span class="pln">score   support

</span><span class="lit">0</span><span class="pln">                 </span><span class="lit">0.67</span><span class="pln">      </span><span class="lit">0.64</span><span class="pln">      </span><span class="lit">0.66</span><span class="pln">        </span><span class="lit">59</span><span class="pln">
</span><span class="lit">1</span><span class="pln">                 </span><span class="lit">0.95</span><span class="pln">      </span><span class="lit">0.96</span><span class="pln">      </span><span class="lit">0.95</span><span class="pln">       </span><span class="lit">441</span><span class="pln">

avg </span><span class="pun">/</span><span class="pln"> total       </span><span class="lit">0.92</span><span class="pln">      </span><span class="lit">0.92</span><span class="pln">      </span><span class="lit">0.92</span><span class="pln">       </span><span class="lit">500</span><span class="pln">

</span><span class="typ">Overall</span><span class="pln"> </span><span class="typ">Accuracy</span><span class="pun">:</span><span class="pln"> </span><span class="lit">0.92</span></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>By using the <code>random_state</code> attribute, you ensure that your results remain the same every time you re-run this script. Otherwise, if removed, you may notice that your results are different to the ones presented here (and will be different every time you run this script). This is due to the random nature of random forests, since every predictor is trained with a bootstrap of the data, which is a random sampling with replacement. Also, in every tree there is some randomness in how the subset of attributes for training is selected.</p>
</li>
</ol>
</div>
</div>
<div class="sect2 activity">
<h3 id="_visualising_the_rf_accuracy">Visualising the RF accuracy</h3>
<div class="paragraph">
<p>You can also visualise how the overall test accuracy is affected by increase in <code>n_estimators</code> (the number of decision trees) in your model. In order to do so, you can use the provided <code>rfAvgAcc</code> function from <code>visplots</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Visualise average accuracy with an increasing number of trees</span><span class="pln">

visplots</span><span class="pun">.</span><span class="pln">rfAvgAcc</span><span class="pun">(</span><span class="pln">rfModel</span><span class="pun">=</span><span class="pln">rf</span><span class="pun">,</span><span class="pln"> </span><span class="typ">XTest</span><span class="pun">=</span><span class="typ">XTest</span><span class="pun">,</span><span class="pln"> yTest</span><span class="pun">=</span><span class="pln">yTest</span><span class="pun">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This results in the following output:</p>
</div>
<div id="mod3_treePerformance" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod3_treePerformance.png" alt="Random Forest Performance" width="720">
</div>
<div class="title">Figure 6. Average testing accuracy with the increasing number of decision trees in the Random Forest.</div>
</div>
</div>
<div class="sect2 activity">
<h3 id="_feature_importance">Feature importance</h3>
<div class="paragraph">
<p>Random forests allow you to compute a heuristic for determining how â€œimportantâ€ a feature is in predicting a target. This heuristic measures the change in prediction accuracy when a split is introduced in a given feature. The more the accuracy drops when the feature is splitted, the more â€œimportantâ€ we deem the feature to be.</p>
</div>
<div class="paragraph">
<p>You can use the <code>feature_importances_</code> attribute of the RF classifier to get the relative importance of each feature, which you can then visualise using a simple bar plot.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Display the importance of the features in a barplot</span><span class="pln">

</span><span class="com"># sorting the features according their importance</span><span class="pln">
importance_sorted_idx </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">argsort</span><span class="pun">(</span><span class="pln">rf</span><span class="pun">.</span><span class="pln">feature_importances_</span><span class="pun">)</span><span class="pln"> </span><b class="conum"><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span></b><span class="pln">
names </span><span class="pun">=</span><span class="pln"> header</span><span class="pun">[</span><span class="lit">0</span><span class="pun">:</span><span class="lit">10</span><span class="pun">]</span><span class="pln">

data </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="pln">
    </span><span class="typ">Bar</span><span class="pun">(</span><span class="pln">
        x</span><span class="pun">=</span><span class="pln">rf</span><span class="pun">.</span><span class="pln">feature_importances_</span><span class="pun">[</span><span class="pln">importance_sorted_idx</span><span class="pun">],</span><span class="pln">
        y</span><span class="pun">=</span><span class="pln">names</span><span class="pun">[</span><span class="pln">importance_sorted_idx</span><span class="pun">],</span><span class="pln">
        orientation </span><span class="pun">=</span><span class="pln"> </span><span class="str">'h'</span><span class="pun">,</span><span class="pln">
    </span><span class="pun">)</span><span class="pln">
</span><span class="pun">]</span><span class="pln">

layout </span><span class="pun">=</span><span class="pln"> </span><span class="typ">Layout</span><span class="pun">(</span><span class="pln">
    xaxis</span><span class="pun">=</span><span class="pln">dict</span><span class="pun">(</span><span class="pln">title </span><span class="pun">=</span><span class="pln"> </span><span class="str">"Importance of features"</span><span class="pun">),</span><span class="pln">
    yaxis</span><span class="pun">=</span><span class="pln">dict</span><span class="pun">(</span><span class="pln">title </span><span class="pun">=</span><span class="pln"> </span><span class="str">"Features"</span><span class="pun">),</span><span class="pln">
    width</span><span class="pun">=</span><span class="lit">800</span><span class="pun">,</span><span class="pln">
    margin</span><span class="pun">=</span><span class="typ">Margin</span><span class="pun">(</span><span class="pln">
        l</span><span class="pun">=</span><span class="lit">250</span><span class="pun">,</span><span class="pln">
        r</span><span class="pun">=</span><span class="lit">50</span><span class="pun">,</span><span class="pln">
        b</span><span class="pun">=</span><span class="lit">100</span><span class="pun">,</span><span class="pln">
        t</span><span class="pun">=</span><span class="lit">50</span><span class="pun">,</span><span class="pln">
        pad</span><span class="pun">=</span><span class="lit">4</span><span class="pln">
    </span><span class="pun">)</span><span class="pln">
</span><span class="pun">)</span><span class="pln">

fig </span><span class="pun">=</span><span class="pln"> dict</span><span class="pun">(</span><span class="pln">data</span><span class="pun">=</span><span class="pln">data</span><span class="pun">,</span><span class="pln"> layout</span><span class="pun">=</span><span class="pln">layout</span><span class="pun">)</span><span class="pln">

iplot</span><span class="pun">(</span><span class="pln">fig</span><span class="pun">)</span></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p><code>argsort</code> returns the indices that would sort the features by their importance.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Which results in the following graph:</p>
</div>
<div id="mod3_featureImportance" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod3_featureImportance.png" alt="Random Forest Feature Importance">
</div>
<div class="title">Figure 7. How â€œimportantâ€ a feature is in predicting a target.</div>
</div>
</div>
<div class="sect2 activity">
<h3 id="_boundary_visualisation">Boundary visualisation</h3>
<div class="paragraph">
<p>You can visualise the classification boundary created by the Random Forest using the <code>visplots.rfDecisionPlot</code> function. You can check the arguments passed in this function by using the <code>help</code> command. In addition to the mandatory arguments, the function <code>visplots.rfDecisionPlot</code> takes as optional arguments the ones from the <code>RandomForestClassifier</code> function, so you can have a look at the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">documentation</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com">#### Check the arguments of the function</span><span class="pln">
help</span><span class="pun">(</span><span class="pln">visplots</span><span class="pun">.</span><span class="pln">rfDecisionPlot</span><span class="pun">)</span><span class="pln">

</span><span class="com"># Plot the boundary of Random Forest</span><span class="pln">
visplots</span><span class="pun">.</span><span class="pln">rfDecisionPlot</span><span class="pun">(</span><span class="typ">XTrain</span><span class="pun">,</span><span class="pln"> yTrain</span><span class="pun">,</span><span class="pln"> </span><span class="typ">XTest</span><span class="pun">,</span><span class="pln"> yTest</span><span class="pun">,</span><span class="pln"> header</span><span class="pun">,</span><span class="pln"> n_estimators</span><span class="pun">=</span><span class="lit">150</span><span class="pun">)</span></code></pre>
</div>
</div>
<div id="mod3_rf_boundary" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod3_rf_boundary.png" alt="random_forest" width="540">
</div>
<div class="title">Figure 8. Decision boundary for a Random Forest classifier</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Boundary interpretation</div>
<div class="paragraph">
<p>A Random Forest boundary will be the union of the intersection of the decision boundaries of many decision trees (remember that the decision region for a decision tree is rectilinear with "stair-like" or "box-like" surfaces). Therefore, the  decision region of a Random Forest also has a rectilinear boundary composed of axis-parallel segments.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_parameter_tuning_and_grid_search">Parameter tuning and grid search</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Many classification algorithms and pattern recognition techniques have one or more parameters that need to be tuned. Such parameters are often referred to as <em>hyperparameters</em>. They are called <em>hyperparameters</em> as they are not parameters that are adapted internally as the Machine Learning algorithm is applied, rather we have to set them to values that we want to explore.</p>
</div>
<div class="paragraph">
<p>Selecting the optimal values of these parameters - a process commonly referred to as "<strong>tuning</strong>" -
for a given classification problem is no trivial task, and can greatly affect a modelâ€™s performance.
A common approach towards optimising the hyperparameters is to apply a "three-way split",
where one subset (usually 30% of the data using a holdout approach) of the original data is left aside during
the whole training process  as a <strong>test</strong> set to evaluate the generalisation ability of the model,
whereas the remaining data are further split into <strong>training</strong> (used to fit the model) and <strong>validation</strong>
(used to tune the model parameters) dataset(s) using holdout or <strong>cross-validation</strong> (or other validation techniques).</p>
</div>
<div id="module4_paramterstuning" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod4_3Split.png" alt="mod4 3Split" width="650">
</div>
<div class="title">Figure 9. Summary of the process of optimal parameters selection. For each parameter combination, the data are split into training and test sets a specified number of times. The accuracy is then calculated from the mean of the models trained and evaluated on these splits, i.e. given a cross validation accuracy score. The best parameter combination is the one with the highest cross validation accuracy score. The figure has been extracted from <a href="http://online.cambridgecoding.com/notebooks/cca_admin/misleading-modelling-overfitting-crossvalidation-and-the-biasvariance-tradeoff">this tutorial</a>.</div>
</div>
<div class="sect2">
<h3 id="_k_fold_cross_validation">K-fold cross-validation</h3>
<div class="paragraph">
<p><a id="k-fold_cross-validation"></a>K-fold <a id="Cross-validation"></a>cross-validation is a way of â€œcross-validatingâ€ your model. Cross-validation allows you to estimate the performance of your model when presented with completely unseen (real) test data using the dataset you are given. You do this by repeatedly splitting your dataset up into training and (pseudo-)"test" sets and then evaluating the accuracy each time, i.e. each time, one proportion of your dataset will â€œpretendâ€ to be coming from outside the dataset. By repeating the validation process for different splits of the data, you can have more confidence that your estimate of the modelâ€™s accuracy will generalise and that it will be "robust".</p>
</div>
<div class="paragraph">
<p>The K in K-fold validation refers to the number of times you will be splitting the data. For example, if K=3:</p>
</div>
<div id="module4_kfold" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod4_cv.png" alt="kfold" width="470">
</div>
<div class="title">Figure 10. K-fold validation where K=3. Accuracy is calculated for the model trained from each split so that in the case of K=3, a1 is the accuracy of the model trained on the first split, a2 is the accuracy of the model trained on the second split, and a3 is the accuracy of the model trained on the third split.</div>
</div>
<div class="paragraph">
<p>The accuracy is then calculated by taking the average of the accuracies of the models trained on each split, i.e. the mean of a1, a2 and a3.</p>
</div>
</div>
<div class="sect2">
<h3 id="_grid_search">Grid search</h3>
<div class="paragraph">
<p>The traditional way of performing hyperparameter optimisation is by applying grid search,
which is simply an exhaustive searching through a manually specified subset
of the hyperparameter space of a learning algorithm.
A grid search algorithm must be guided by some performance metric,
typically measured by cross-validation on the training set or evaluation on a held-out validation set.</p>
</div>
<div id="module4_paramterstuning" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod4_hp.png" alt="mod4 hp" width="650">
</div>
<div class="title">Figure 11. In the context of hyperparameter optimization, you perform k-fold cross validation together with grid search to get a more robust estimate of the model performance associated with specific hyperparameter values. The figure has been extracted from <a href="https://blog.cambridgecoding.com/2016/04/03/scanning-hyperspace-how-to-tune-machine-learning-models/" class="bare">https://blog.cambridgecoding.com/2016/04/03/scanning-hyperspace-how-to-tune-machine-learning-models/</a></div>
</div>
</div>
<div class="sect2 activity">
<h3 id="_tuning_random_forests_with_grid_search">Tuning Random Forests with grid search</h3>
<div class="paragraph">
<p>Random forests have several parameters that can be tuned, e.g. <code>n_estimators</code>, <code>max_features</code>, <code>max_depth</code> and <code>min_samples_leaf</code> (the minimum number of samples in a leaf) are just some of the parameters to be optimised. To view the full list of arguments that can be optimised for a Random Forest, you can use the <code>help()</code> function:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># View the list of arguments to be optimised</span><span class="pln">

help</span><span class="pun">(</span><span class="typ">RandomForestClassifier</span><span class="pun">())</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Here are the main parameters that you can tune:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>n_estimators</strong>: The number of trees in the forest. A larger number of trees is preferable as it will decrease the variance in predictions, but it is also more computationally expensive. In addition, results will stop getting significantly better beyond a critical number of trees.</p>
</li>
<li>
<p><strong>max_features</strong>: The size of the random subsets of features to consider when splitting a node. The smaller the subset of features is, the greater the reduction of variance, but also the greater the increase in bias. Empirically, it has been found that good default values are <code>max_features=sqrt(n_features)</code> (default case) for classification tasks (where <code>n_features</code> is the number of features in the data).</p>
</li>
<li>
<p><strong>max_depth</strong>: The maximum number of links between the root of the tree and the leaves. The smaller it is, the simpler the decision boundary will be.</p>
</li>
<li>
<p><strong>min_sample_split</strong>: The minimum number of samples required to split an internal node, by default this is set to 2 in scikit-learn resulting in fully developed trees.</p>
</li>
<li>
<p><strong>min_samples_leaf</strong>: The minimum number of samples required to be at a leaf node, by default this is set to 1. Increasing this value can result in leaves that contain more samples and, in some cases, can prevent the overfitting of a tree.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Good results are often achieved when setting <code>max_depth=None</code> in combination with <code>min_samples_split=1</code>. Bear in mind though that using these values might result in models that consume a lot of memory. In addition, note that with scikit-learn, the RandomForestClassifier uses bootstrap samples by default (<code>bootstrap=True</code>). (This is not the case for the ExtraTreeClassifier, where <code>bootstrap=False</code> by default).</p>
</div>
<div class="paragraph">
<p>Remember, the best parameter values should always be <strong>cross-validated</strong>. The grid search evaluates the RF classifier for every possible combination of parameters specified by the dictionary parameters using 10-fold cross-validation. Precision is used as the measure to evaluate the model and find the best parameter set:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Conduct a grid search with 5-fold cross-validation using the dictionary of parameters</span><span class="pln">

</span><span class="com"># Parameters you can investigate include:</span><span class="pln">
n_estimators </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">arange</span><span class="pun">(</span><span class="lit">5</span><span class="pun">,</span><span class="pln"> </span><span class="lit">100</span><span class="pun">,</span><span class="pln"> </span><span class="lit">25</span><span class="pun">)</span><span class="pln">
max_depth    </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">arange</span><span class="pun">(</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">35</span><span class="pun">,</span><span class="pln"> </span><span class="lit">5</span><span class="pun">)</span><span class="pln">
</span><span class="com"># percentage of features to consider at each split</span><span class="pln">
max_features </span><span class="pun">=</span><span class="pln"> np</span><span class="pun">.</span><span class="pln">linspace</span><span class="pun">(.</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1.</span><span class="pun">,</span><span class="lit">3</span><span class="pun">)</span><span class="pln">
parameters   </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[{</span><span class="str">'n_estimators'</span><span class="pun">:</span><span class="pln"> n_estimators</span><span class="pun">,</span><span class="pln">
                 </span><span class="str">'max_depth'</span><span class="pun">:</span><span class="pln"> max_depth</span><span class="pun">,</span><span class="pln">
                 </span><span class="str">'max_features'</span><span class="pun">:</span><span class="pln"> max_features</span><span class="pun">}]</span><span class="pln">

gridCV </span><span class="pun">=</span><span class="pln"> </span><span class="typ">GridSearchCV</span><span class="pun">(</span><span class="typ">RandomForestClassifier</span><span class="pun">(),</span><span class="pln"> param_grid</span><span class="pun">=</span><span class="pln">parameters</span><span class="pun">,</span><span class="pln"> cv</span><span class="pun">=</span><span class="lit">5</span><span class="pun">,</span><span class="pln"> n_jobs</span><span class="pun">=</span><span class="lit">4</span><span class="pun">)</span><span class="pln"> </span><span class="pun">(</span><span class="lit">1</span><span class="pun">)</span><span class="pln">
gridCV</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="typ">XTrain</span><span class="pun">,</span><span class="pln"> yTrain</span><span class="pun">)</span><span class="pln">

</span><span class="com"># Print the optimal parameters</span><span class="pln">
best_n_estim      </span><span class="pun">=</span><span class="pln"> gridCV</span><span class="pun">.</span><span class="pln">best_params_</span><span class="pun">[</span><span class="str">'n_estimators'</span><span class="pun">]</span><span class="pln">
best_max_depth    </span><span class="pun">=</span><span class="pln"> gridCV</span><span class="pun">.</span><span class="pln">best_params_</span><span class="pun">[</span><span class="str">'max_depth'</span><span class="pun">]</span><span class="pln">
best_max_features </span><span class="pun">=</span><span class="pln"> gridCV</span><span class="pun">.</span><span class="pln">best_params_</span><span class="pun">[</span><span class="str">'max_features'</span><span class="pun">]</span><span class="pln">

</span><span class="kwd">print</span><span class="pln"> </span><span class="pun">(</span><span class="str">'Best parameters: n_estimators='</span><span class="pun">,</span><span class="pln"> best_n_estim</span><span class="pun">,</span><span class="pln">
       </span><span class="str">'max_depth='</span><span class="pun">,</span><span class="pln"> best_max_depth</span><span class="pun">,</span><span class="pln">
       </span><span class="str">'max_features='</span><span class="pun">,</span><span class="pln"> best_max_features</span><span class="pun">)</span><span class="pln">

</span><span class="pun">&gt;</span><span class="pln"> </span><span class="typ">Best</span><span class="pln"> parameters</span><span class="pun">:</span><span class="pln"> n_estimators</span><span class="pun">=</span><span class="lit">80</span><span class="pln"> max_depth</span><span class="pun">=</span><span class="lit">6</span><span class="pln"> max_features</span><span class="pun">=</span><span class="lit">1.0</span><span class="pln"> </span><b class="conum"><span class="pun">(</span><span class="lit">2</span><span class="pun">)</span></b></code></pre>
</div>
</div>
<div class="colist arabic">
<ol>
<li>
<p>The <code>n_jobs</code> argument can be used for parallelisation to speed up the tuning process.</p>
</li>
<li>
<p>You may notice that your results are different from the ones presented here (affecting also the overall accuracy and relevant metrics) since we havenâ€™t used the <code>random_state</code> argument within the <code>RandomForestClassifier</code> to ensure the results remain the same every time we run this script.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>You may also choose to include in your dictionary of parameters and grid search any of the following options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Additional parameters to investigate could include</span><span class="pln">
</span><span class="com"># max_features = [1, 3, 10] or max_features: ['auto', 'sqrt', 'log2']</span><span class="pln">
</span><span class="com"># min_samples_split = [1, 3, 10]</span><span class="pln">
</span><span class="com"># min_samples_leaf  = [1, 3, 10]</span><span class="pln">
</span><span class="com"># bootstrap = [True, False]</span><span class="pln">
</span><span class="com"># criterion = ["gini", "entropy"]</span></code></pre>
</div>
</div>
</div>
<div class="sect2 activity">
<h3 id="_visualising_the_grid_search_results_in_a_heatmap">Visualising the grid search results in a heatmap</h3>
<div class="paragraph">
<p>You can also graphically represent the results of the grid search using a heatmap:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Create a heatmap to visualise the results of the grid search with cross-validation</span><span class="pln">

</span><span class="com"># isolating the the results with the best value of max_features</span><span class="pln">
scores_best_max_features </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="pln">s </span><span class="kwd">for</span><span class="pln"> s </span><span class="kwd">in</span><span class="pln"> gridCV</span><span class="pun">.</span><span class="pln">grid_scores_ </span><span class="kwd">if</span><span class="pln"> s</span><span class="pun">[</span><span class="lit">0</span><span class="pun">][</span><span class="str">'max_features'</span><span class="pun">]</span><span class="pln"> </span><span class="pun">==</span><span class="pln"> best_max_features</span><span class="pun">]</span><span class="pln">
scores </span><span class="pun">=</span><span class="pln"> visplots</span><span class="pun">.</span><span class="pln">rf_organise_scores</span><span class="pun">(</span><span class="pln">scores_best_max_features</span><span class="pun">,</span><span class="pln"> n_estimators</span><span class="pun">,</span><span class="pln"> max_depth</span><span class="pun">)</span><span class="pln">

data </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="pln">
    </span><span class="typ">Heatmap</span><span class="pun">(</span><span class="pln">
        x</span><span class="pun">=</span><span class="pln">n_estimators</span><span class="pun">,</span><span class="pln">
        y</span><span class="pun">=</span><span class="pln">max_depth</span><span class="pun">,</span><span class="pln">
        z</span><span class="pun">=</span><span class="pln">scores</span><span class="pun">.</span><span class="pln">T</span><span class="pun">,</span><span class="pln">
        colorscale</span><span class="pun">=</span><span class="str">'Blues'</span><span class="pun">,</span><span class="pln">
        reversescale</span><span class="pun">=</span><span class="kwd">True</span><span class="pun">,</span><span class="pln">
        colorbar</span><span class="pun">=</span><span class="pln">dict</span><span class="pun">(</span><span class="pln">
            title</span><span class="pun">=</span><span class="str">"Classification Accuracy"</span><span class="pun">,</span><span class="pln">
            nticks</span><span class="pun">=</span><span class="lit">10</span><span class="pln">
        </span><span class="pun">)</span><span class="pln">
    </span><span class="pun">)</span><span class="pln">
</span><span class="pun">]</span><span class="pln">

layout </span><span class="pun">=</span><span class="pln"> </span><span class="typ">Layout</span><span class="pun">(</span><span class="pln">
    xaxis </span><span class="pun">=</span><span class="pln"> dict</span><span class="pun">(</span><span class="pln">title</span><span class="pun">=</span><span class="str">"Number of estimators"</span><span class="pun">,</span><span class="pln"> tickvals</span><span class="pun">=</span><span class="pln">n_estimators</span><span class="pun">),</span><span class="pln">
    yaxis </span><span class="pun">=</span><span class="pln"> dict</span><span class="pun">(</span><span class="pln">title</span><span class="pun">=</span><span class="str">"Max Depth"</span><span class="pun">,</span><span class="pln"> tickvals</span><span class="pun">=</span><span class="pln"> max_depth</span><span class="pun">),</span><span class="pln">
    height </span><span class="pun">=</span><span class="pln"> </span><span class="lit">700</span><span class="pun">,</span><span class="pln">
</span><span class="pun">)</span><span class="pln">

fig </span><span class="pun">=</span><span class="pln"> dict</span><span class="pun">(</span><span class="pln">data</span><span class="pun">=</span><span class="pln">data</span><span class="pun">,</span><span class="pln"> layout</span><span class="pun">=</span><span class="pln">layout</span><span class="pun">)</span><span class="pln">

iplot</span><span class="pun">(</span><span class="pln">fig</span><span class="pun">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Your plot may look as follows:</p>
</div>
<div id="mod3_rf_heatmap" class="imageblock" style="text-align: center">
<div class="content">
<img src="./04-Decision Trees and Random Forests_files/mod3_rf_heatmap.png" alt="mod3_rf_heatmap">
</div>
<div class="title">Figure 12. Grid search scores from the tuning of the RF hyperparameters</div>
</div>
</div>
<div class="sect2 activity">
<h3 id="_testing_and_evaluating_the_generalisation_performance">Testing and evaluating the generalisation performance</h3>
<div class="paragraph">
<p>When evaluating the resulting model it is important to do it on held-out samples
that were not seen during the grid search process (<em>XTest</em>). So, we are testing our independent <em>XTest</em> dataset using the optimal parameters:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="com"># Build the classifier using the *optimal* parameters detected by grid search</span><span class="pln">

clfRDF </span><span class="pun">=</span><span class="pln"> </span><span class="typ">RandomForestClassifier</span><span class="pun">(</span><span class="pln">n_estimators</span><span class="pun">=</span><span class="pln">best_n_estim</span><span class="pun">,</span><span class="pln">
                                max_depth</span><span class="pun">=</span><span class="pln">best_max_depth</span><span class="pun">,</span><span class="pln">
                                max_features </span><span class="pun">=</span><span class="pln"> best_max_features</span><span class="pun">)</span><span class="pln">

clfRDF</span><span class="pun">.</span><span class="pln">fit</span><span class="pun">(</span><span class="typ">XTrain</span><span class="pun">,</span><span class="pln"> yTrain</span><span class="pun">)</span><span class="pln">
predRF </span><span class="pun">=</span><span class="pln"> clfRDF</span><span class="pun">.</span><span class="pln">predict</span><span class="pun">(</span><span class="typ">XTest</span><span class="pun">)</span><span class="pln">

</span><span class="kwd">print</span><span class="pln"> </span><span class="pun">(</span><span class="pln">metrics</span><span class="pun">.</span><span class="pln">classification_report</span><span class="pun">(</span><span class="pln">yTest</span><span class="pun">,</span><span class="pln"> predRF</span><span class="pun">))</span><span class="pln">
</span><span class="kwd">print</span><span class="pln"> </span><span class="pun">(</span><span class="str">"Overall Accuracy:"</span><span class="pun">,</span><span class="pln"> round</span><span class="pun">(</span><span class="pln">metrics</span><span class="pun">.</span><span class="pln">accuracy_score</span><span class="pun">(</span><span class="pln">yTest</span><span class="pun">,</span><span class="pln"> predRF</span><span class="pun">),</span><span class="lit">2</span><span class="pun">))</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Which may result in the following output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="prettyprint highlight prettyprinted"><code class="language-python" data-lang="python"><span class="pln">                precision    recall  f1</span><span class="pun">-</span><span class="pln">score   support

</span><span class="lit">0</span><span class="pln">                 </span><span class="lit">0.66</span><span class="pln">      </span><span class="lit">0.63</span><span class="pln">      </span><span class="lit">0.64</span><span class="pln">        </span><span class="lit">59</span><span class="pln">
</span><span class="lit">1</span><span class="pln">                 </span><span class="lit">0.95</span><span class="pln">      </span><span class="lit">0.96</span><span class="pln">      </span><span class="lit">0.95</span><span class="pln">       </span><span class="lit">441</span><span class="pln">

avg </span><span class="pun">/</span><span class="pln"> total       </span><span class="lit">0.92</span><span class="pln">      </span><span class="lit">0.92</span><span class="pln">      </span><span class="lit">0.92</span><span class="pln">       </span><span class="lit">500</span><span class="pln">

</span><span class="typ">Overall</span><span class="pln"> </span><span class="typ">Accuracy</span><span class="pun">:</span><span class="pln"> </span><span class="lit">0.92</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_wrap_up_of_module_4">Wrap up of Module 4</h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>A decision tree model consists of a root node, internal nodes and terminal (leaf) nodes. Root nodes and internal nodes contain feature test conditions, while terminal nodes assign the class label.</p>
</li>
<li>
<p>Decision Trees are interpretable classification models.</p>
</li>
<li>
<p>Random Forests reduce variance by combining many independently trained decision trees by averaging or majority voting. The individual trees are trained on data from bootstrap sampling with replacement.</p>
</li>
<li>
<p>Random Forests, like other "ensemble learning" methods, use many models from the training data to make predictions. In the case of random forests, the individual models are decision trees.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2016-11-25 06:32:37 GMT
</div>
</div>
<link rel="stylesheet" href="./04-Decision Trees and Random Forests_files/prettify.min.css">
<script src="./04-Decision Trees and Random Forests_files/prettify.min.js"></script>
<script>prettyPrint()</script>
<script type="text/x-mathjax-config;executed=true">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
});
</script>
<script src="./04-Decision Trees and Random Forests_files/MathJax.js"></script>

<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: STIXSizeOneSym, sans-serif;"></div></div></body><div></div></html>